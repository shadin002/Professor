{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L8AdqVK0g6y7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab76ea70-50e1-4881-ab61-eb9e3218daa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor\n",
        "x = torch.tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "print(x)\n",
        "print(x.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import shutil, os\n",
        "\n",
        "os.makedirs(\"/content/data/flower\", exist_ok=True)\n",
        "\n",
        "shutil.copy(\n",
        "    \"/content/flower1.jpg\",\n",
        "    \"/content/data/flower/flower1.jpg\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "o9H3I1DG-nNv",
        "outputId": "b4a37b23-1eef-4405-c0c5-5b78a27d1cef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data/flower/flower1.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.images = os.listdir(image_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = 0  # dummy label for now\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "cZCzO3hWH1WV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "dataset = SimpleImageDataset(\"/content/data/flower\", transform)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "3RH81sR4H4Bj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "model.fc = torch.nn.Identity()\n",
        "model.eval()\n",
        "\n",
        "images, labels = next(iter(dataloader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    features = model(images)\n",
        "\n",
        "print(\"Image batch:\", images.shape)\n",
        "print(\"Extracted features:\", features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X5wP1ZdH7Zk",
        "outputId": "0cef2408-c1c3-41b9-99d0-db761a92185b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 118MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch: torch.Size([1, 3, 224, 224])\n",
            "Extracted features: torch.Size([1, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 56 * 56, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-QUbGvKyQ7Bo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1):  # 1 epoch for understanding\n",
        "    for images, labels in dataloader:\n",
        "\n",
        "        optimizer.zero_grad()        # reset gradients\n",
        "        outputs = model(images)      # forward pass\n",
        "        loss = criterion(outputs, labels)  # compute loss\n",
        "        loss.backward()              # backpropagation\n",
        "        optimizer.step()             # update weights\n",
        "\n",
        "        print(\"Loss:\", loss.item())\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in dataloader:\n",
        "        outputs = model(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFEZt3cFRGqu",
        "outputId": "992fc6fd-9e85-4dbd-e2c4-8491a15fa9b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.626800000667572\n"
          ]
        }
      ]
    }
  ]
}