{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L8AdqVK0g6y7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "734336db-a369-44a2-f5ef-a52de9266d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor\n",
        "x = torch.tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "print(x)\n",
        "print(x.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import shutil, os\n",
        "\n",
        "os.makedirs(\"/content/data/flower\", exist_ok=True)\n",
        "\n",
        "shutil.copy(\n",
        "    \"/content/flower1.jpg\",\n",
        "    \"/content/data/flower/flower1.jpg\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "o9H3I1DG-nNv",
        "outputId": "571cb412-4f60-464e-8c44-2abc55c414a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data/flower/flower1.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.images = os.listdir(image_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = 0  # dummy label for now\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "cZCzO3hWH1WV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "dataset = SimpleImageDataset(\"/content/data/flower\", transform)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "3RH81sR4H4Bj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "model.fc = torch.nn.Identity()\n",
        "model.eval()\n",
        "\n",
        "images, labels = next(iter(dataloader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    features = model(images)\n",
        "\n",
        "print(\"Image batch:\", images.shape)\n",
        "print(\"Extracted features:\", features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X5wP1ZdH7Zk",
        "outputId": "f2b0355a-31c7-4306-a464-6f853495ec76"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch: torch.Size([1, 3, 224, 224])\n",
            "Extracted features: torch.Size([1, 512])\n"
          ]
        }
      ]
    }
  ]
}